[plugin]
name = "siglip"
display_name = "SigLIP"
version = "1.0.0"
description = "Google SigLIP vision-language model for zero-shot image tagging with confidence scores"
entry_point = "SigLIPPlugin"
python_requires = ">=3.11"
# SigLIP provides actual confidence scores via sigmoid activation
# NOTE: SigLIP outputs independent probabilities per label (not softmax)
# Typical confidence range: 0.01-0.10 for matches, use lower thresholds
provides_confidence = true
# Recommended threshold for SigLIP (lower than other models due to sigmoid output)
recommended_threshold = 0.01

[plugin.dependencies]
torch = ">=2.0"
transformers = ">=4.47.0"
pillow = ">=10.0.0"
accelerate = ">=0.25.0"

[plugin.hardware]
gpu_recommended = true
min_ram_gb = 4
min_vram_gb = 2

# Model configuration - these are the user-configurable settings
[plugin.config]
# Model variant to use (affects accuracy vs speed/memory)
# Options:
#   "base" - 86M params, 224x224, fast/low VRAM
#   "large" - 303M params, 512x512, higher accuracy
#   "so400m" - 400M params, 384x384, best balance (RECOMMENDED)
#   "giant" - 1B params, 384x384, maximum accuracy
model_variant = "so400m"

# Attention implementation (affects speed/memory)
# Options: "auto", "sdpa", "flash_attention_2", "eager"
# "auto" detects best available
attention = "auto"

# Data type for inference
# Options: "auto", "float16", "bfloat16", "float32"
# "auto" picks best for your hardware
dtype = "auto"

# Quantization mode for low VRAM systems
# Options: "none", "8bit", "4bit"
# Reduces VRAM by ~50% (8bit) or ~75% (4bit)
quantization = "none"

# NaFlex-specific: max patches for variable resolution
# Range: 64-512, higher = more detail for non-square images
# Only applies when using naflex model variants
max_num_patches = 256
